---
layout: page
assets: "./assets/001/"
title: "Volume 1: The Tortured Self"
subtitle: "Digital Performance"
datetime: "Sat Jan 28 2017 20:00:00 GMT-0400"
location: 
  name: "200 Morgan Ave"
  url: "http://www.umbrellafactory.studio/"
permalink: /test
description: >
  Technology is enmeshed. People are enmeshed. Confusion emerges: what exactly does it mean to be enmeshed? <em>Where does all the mesh come from?</em> The result is a tortured self.
links:
  - name: "facebook"
    url: "https://www.facebook.com/events/705780369577303"
  - name: "RSVP"
    url: "https://www.eventbrite.com/e/mixed-signals-tickets-31331092140"

performances:
  - name: "Isomorphs"
    performers:
      - name: "Matthew Gantt"
        url: "http://gantt.works"
    image: "/images/gantt.jpg"
    description: >
      Isomorphs is an investigation into the plasticity of the relationship between meaning and stimulus in the post-digital age. Drawing material from a variety of 'functional' media, including commonly used ringtones, alarms, and a variety of western cultural signifiers (arena-rock guitar, auto-tune sludge, etc), these sources are analyzed for melodic and gestural information via audio-to-MIDI processes, then re-mapped onto various compositional parameters and re-presented in both raw and manipulated states.

    media: >
      <iframe height="113" width="200" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/255922370&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true"></iframe>

  - name: "In Triplicate"
    url: "http://matt-romein.com/in-triplicate/"
    performers:
      - name: "Matt Romein"
        url: "http://matt-romein.com"
    image: "/images/matt.jpg"
    description: >
      Inspired by the Granular Synthesis work Modell 5, In Triplicate is an exploration in three-dimensional audio-visual sampling of the performer’s face and voice. Contemporary sampling techniques primarily rely on a two-dimensional time axis but by making use of slit-scan techniques the instrument renders multiple moments in time simultaneously. Embracing generative art techniques the instrument hands off a subset of the control parameters and decision making to the computer while keeping the macro control of processes at the performer’s finger tips.
    media: >
      <iframe src="https://player.vimeo.com/video/153056895" width="200" height="113" frameborder='0' webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

  - name: Resonance
    -performers:
      - name: "Dana Abrassart"
        url: "http://www.danaabrassart.com/"
      - name: "Wangshu Sun"
        url: "http://www.sunwangshu.com/"
      - name: "Leo Lan" 
      - name: "Sylvana Tapia"
        url: "http://www.sylvanatapia.com/"
    image: "/images/resonance.jpg"
    description: >
      Resonance is an attempt to express the imperfect, yet emotional tone of our memories through the element of sound. It is a live, motion-scored performance of a memory that has already occurred. Using wireless motion capture technologies, two dancers were recorded during a duet. a single dancer recreates the original performance solo, moving to the memory of her partner. Both her present movements and her remembered interactions of the original performance are translated into sound, creating, live, an entirely unique score with each dance.
    media: >
      <iframe src="https://player.vimeo.com/video/200435486" width="200" height="113" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

  - name: "You Don't Have To Stand"
    url: "http://goldbergs.com/"
    performers:
      - name: Joshua Goldberg
        url: "http://goldbergs.com/"
      - name: Orion Keyser
    image: "/images/stand.jpg"
    description: >
      Orion Keyser is a Music Producer, Recording Engineer & DJ living and working in New York City since 2001, with a Bachelors in Music Composition from the Oberlin Conservatory of Music and releases on seven record labels including Todd Terry's InHouse Records.

      Joshua Goldberg is an experiential designer and live media artist. In the last twenty years, he has, in no particular order, managed and LED-sequenced the most beribboned project in Maker Faire history, programmed museum interactives in states across the country, run a large Burning Man camp, and performed live visuals on personal bespoke software for some of the biggest-name DJs in the world.
    media: >
      <iframe src="https://player.vimeo.com/video/8665849" width="200" height="113" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

background: >
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r83/three.min.js"></script>
  <style type="text/css">
    #container {
      position: fixed;
      z-index: -1;
    }
  </style>
  <div id="container"></div>
  <script id="vertexShader" type="x-shader/x-vertex">
      void main() {
          gl_Position = vec4( position, 1.0 );
      }
  </script>
  <script id="fragmentShader" type="x-shader/x-fragment">
      // #ifdef GL_ES
      // precision mediump float;
      // #endif

      uniform vec2 u_resolution;
      uniform vec2 u_mouse;
      uniform float u_time;

      vec2 random2( vec2 p ) {
          return fract(sin(vec2(dot(p,vec2(127.1,311.7)),dot(p,vec2(269.5,183.3))))*43758.5453);
      }

      void main() {
          vec2 st = gl_FragCoord.xy/u_resolution.xy;
          st.x *= u_resolution.x/u_resolution.y;
          vec3 color = vec3(.0);

          // Scale
          st *= 10.;

          // Tile the space
          vec2 i_st = floor(st);
          vec2 f_st = fract(st);

          float m_dist = 1.;  // minimun distance

          for (int y= -1; y <= 1; y++) {
              for (int x= -1; x <= 1; x++) {
                  // Neighbor place in the grid
                  vec2 neighbor = vec2(float(x),float(y));

                  // Random position from current + neighbor place in the grid
                  vec2 point = random2(i_st + neighbor);

            // Animate the point
                  point = 0.5 + 0.5*sin(0.2*u_time + 6.2831*point);

            // Vector between the pixel and the point
                  vec2 diff = neighbor + point - f_st;

                  // Distance to the point
                  float dist = length(diff);

                  // Keep the closer distance
                  m_dist = min(m_dist, dist);
              }
          }

          // Draw the min distance (distance field)
          color += m_dist;

          // Show isolines
          // color -= step(.7,abs(sin(27.0*m_dist)))*.5;

          color *= sin(m_dist * 100. +   5. * u_time);
          gl_FragColor = vec4(color,1.0);
      }
  </script>
  <script>
      var container;
      var camera, scene, renderer;
      var uniforms;
      var initTime;

      init();
      animate();

      function init() {
          initTime = Date.now();
          container = document.getElementById( 'container' );

          camera = new THREE.Camera();
          camera.position.z = 1;

          scene = new THREE.Scene();

          var geometry = new THREE.PlaneBufferGeometry( 2, 2 );

          uniforms = {
              u_time: { type: "f", value: 1.0 },
              u_resolution: { type: "v2", value: new THREE.Vector2() },
              u_mouse: { type: "v2", value: new THREE.Vector2() }
          };

          var material = new THREE.ShaderMaterial( {
              uniforms: uniforms,
              vertexShader: document.getElementById( 'vertexShader' ).textContent,
              fragmentShader: document.getElementById( 'fragmentShader' ).textContent
          } );

          var mesh = new THREE.Mesh( geometry, material );
          scene.add( mesh );

          renderer = new THREE.WebGLRenderer();
          renderer.setPixelRatio( window.devicePixelRatio );

          container.appendChild( renderer.domElement );

          onWindowResize();
          window.addEventListener( 'resize', onWindowResize, false );

          document.onmousemove = function(e){
            uniforms.u_mouse.value.x = e.pageX
            uniforms.u_mouse.value.y = e.pageY
          }
      }

      function onWindowResize( event ) {
          if (window.innerWidth < 769) {
              renderer.setSize( window.innerWidth, window.innerHeight*2 );
          } else {
              renderer.setSize( window.innerWidth, window.innerHeight );
          }
          uniforms.u_resolution.value.x = renderer.domElement.width;
          uniforms.u_resolution.value.y = renderer.domElement.height;
      }

      function animate() {
          requestAnimationFrame( animate );
          render();
      }

      function render() {
          uniforms.u_time.value = (initTime - Date.now()) / 1000;
          renderer.render( scene, camera );
      }
  </script>
---